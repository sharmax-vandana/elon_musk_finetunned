Interviewer: Okay. All right. Well, good evening, everybody. Welcome. Elon, thanks for being here.
Elon Musk: Thank you for having me.
Interviewer: We feel very privileged. We're excited to have you. Right, so I'm going to start with some questions and then we're going to open it up. Let me get straight into it. So Bill Gates said, there is no one in our time who has done more to push the bounds of science innovation than you. Well, it's kind of going to say, well, that's it. It's a nice thing to have anyone say about you. Nice coming from Bill Gates. But oddly enough, when it comes to AI, actually, for around a decade, you've almost been doing the opposite and saying, hang on, you need to think about what we're doing and what we're pushing here and what do we do to make this safe. And actually, we shouldn't be pushing as fast or as hard as we are. You've been doing it for a decade. What was it that caused you to think about it that way? And why do we need to be worried?
Elon Musk: Yeah, I've been somewhat of a Cassandra for quite a while where people would. I would tell people, like, we should really be concerned about AI. They'd be like, what are you talking about? Like, they've never really had any experience with. With AI, but since I was immersed in technology, I have been immersed in technology for a long time. I could see it coming. So. But I think this year was, there've been a number of breakthroughs. I mean, you know the point at which someone can see a dynamically created video of themselves, somebody could make a video of you saying anything in real time, or me. And so there's sort of the deep fake videos, which are really incredibly good, in fact, sometimes more convincing than real ones. And deep real. And then Obviously things like ChatGPT were quite remarkable. Now I saw GPT1, GPT2, GPT3, GPT4, the whole sort of lead up to that. So it was easy for me to kind of see where it's going. If you just sort of extrapolate the points on a curve and assume that trend will continue, then we will have profound artificial intelligence and obviously at a level that far exceeds human intelligence. But I'm glad to see at this point that people are taking safety seriously. And I'd like to say thank you for holding this AI safety conference. I think actually it will go down in history as being very important. I think it's really quite profound and I do think overall that the potential is there for artificial intelligence AI to have most likely A positive effect and to create a future of abundance where there is no scarcity of goods and services. But it is somewhat of the magic genie problem, where if you have a magic genie that can grant all the wishes, usually those stories don't end well. Be careful what you wish for, including wishes.
Interviewer: So you talked a little bit about the summit and that thank you for being engaged in it, which has been great, and people enjoyed having you there, participating in this dialogue. Now, one of the things that we achieved today in the meetings between the companies and the leaders was an agreement that externally, ideally, governments should be doing safety testing of models before they're released. I think this is something that you've spoken about a little bit. It was something we worked really hard on, because my job in government is to say, hang on, there is a potential risk here, not a definite risk, but a potential risk of something that could be bad. My job is to protect the country, and we can only do that if we develop the capability we need in our Safety Institute and then go in and make sure we can test the models before they are released. Delighted that that happened today. But what's your view on what we should be doing? Right. You've talked about the potential risk, right? Again, we don't know. But what are the types of things governments like ours should be doing to manage and mitigate against those risks?
Elon Musk: Well, I generally think that it is good for government to play a role when the public safety is at risk. So really, for the vast majority of software, the public safety is not at risk. I mean, if the app crashes on your phone or your laptop, it's not a massive catastrophe. But when talking about digital superintelligence, I think, which does pose a risk to the public, then there is a role for government to play to safeguard the interests of the public. And this is, of course, true in many fields. Aviation, cars. I deal with regulators throughout the world because of Starlink being communications, rockets being aerospace, and cars being vehicle transport. So I'm very familiar with dealing with regulators, and I actually agree with the vast majority of regulations. There's a few that I disagree with from time to time, but 0.1%, probably less than 1% of regulations I disagree with. So there is some concern from people in Silicon Valley who have never dealt with regulators before, and they think that this is going to just crush innovation and slow them down and be annoying. And it will be annoying. It's true. They're not wrong about that. But. But I think we've learned over the years that having a referee is A good thing. And if you look at any sports game, there's always a referee. And nobody's suggesting, I think, to have a sports game without one. And I think that's the right way to think about this, is for govern to be a referee, to make sure the sportsmanlike conduct and that the public safety is addressed, that we care about public safety, because I think there might be at times too much optimism about technology. And I say that as a technologist. I mean, so I ought to know. And like I said, on balance, I think that the AI will be a force for good, most likely, but the probability of it going bad is not zero percent. So we just need to mitigate the downside potential.
Interviewer: And then how you talk about referee and that's what we're talking about. Yeah, well, there we go. I mean, you know, we talked about this and Demis and I discussed this.
Elon Musk: A long time ago, like literally facing right at him.
Interviewer: And actually, you know, Demis, to his credit and the credit of people in the industry, did say that to us. It's not right that Demis and his colleagues are marking their own homework. Right. There needs to be some. Someone independent. And that's why we've developed the Safety Institute here. Do you think governments can develop the expertise? One of the things we need to do is say, hang on, Demis, Sam, all the others have got a lot of very smart people doing this. Governments need to quickly tool up, capability wise, personnel wise, which is what we're doing. Do you think it is possible for governments to do that fast enough, given how quickly the technology is developing, or what do we need to do to make sure we do do it quick enough?
Elon Musk: No, I think it's a great point you're making. The pace of AI is faster than any technology I've seen in history, by far, and it seems to be growing in capability by at least five fold, perhaps tenfold per year. It'll certainly grow by an order of magnitude next year.
Interviewer: Yeah.
Elon Musk: And government isn't used to moving at that speed. But I think even if there are not firm regulations, even if there isn't an enforcement capability, simply having insight and being able to highlight concerns to the public will be very powerful. So even if that's all that's accomplished, I think that will be very, very good.
Interviewer: Okay. Yeah. Well, hopefully we can do better than that.
Elon Musk: Hopefully, yeah.
Interviewer: Yeah. No, but that's how far I share. We were talking before. It was striking. You're someone who spent their life in technology, living Moore's Law. And what was interesting over the last couple of days, talking to everyone who's doing the development of this, and I think you'd concur with this is just the pace of advancement here is unlike anything all of you have seen in your careers in technology. Is that fair? Because you've got these kind of compounding effects from the hardware and the data and the personnel.
Elon Musk: Yeah. I mean, currently the two leading centers for AI development are the San Francisco Bay area and the sort of London area, and there are many other places where it's being done, but those are the two leading areas. So I think if, you know, if the United States and the UK and China are sort of aligned on safety, that's all going to be a good thing because that's really, that's where, that's, that's where the leadership is generally.
Interviewer: I mean, you actually, it's interesting you mentioned China there. So I took a decision to invite China to summit over the last. Very good. And it was not an easy decision. A lot of people criticized me for it. You know, my view is if you're going to try essential serious conversation, you need to. But what would your thoughts? You do business all around the world. You just talked about it there.
Elon Musk: Yeah.
Interviewer: You know, should we be engaging with them? Can we trust them? Is that the right thing to have.
Elon Musk: Done if we don't. If China is not on board with AI safety, it's somewhat of a moot situation. The single biggest objection that I get to any kind of AI regulation or sort of safety controls are, well, China's not going to do it and therefore they will just jump into the lead and exceed us all. But, but actually China is willing to participate in AI safety and thank you for inviting them. And I. And they, you know, I think we should thank China for attending. When I was in China earlier this year, my main subject of discussion with the leadership in China was AI safety and saying that this is really something that they should care about and they took it seriously and you are too, which is great. And having them here, I think was essential. Really, if they're not participants, it's. It's pointless.
Interviewer: It's pointless. Yeah. And I think we were pleased they were engaged yesterday in the discussions and actually ended up signing the same communique that everyone else did. That's great. Which is a good start. Right. We need everyone to approach us in a similar way if we're going to have, I think, a realistic chance of resolving it. I was going to tell you talked about innovation earlier and regulation being annoying. There was a good debate Today we had about open source and I think you've kind of been a proponent of algorithmic transparency and making some of the, the X algorithms public. And actually we were talking about Geoffrey Hinton on the way in. He's particularly been very concerned about open source models being used by bad actors. You've got a group of people who say they are critical to innovation happening in that distributed way. Look, there's probably no perfect answer and there is a tricky balance. What are your thoughts on how we should approach this open source question or where should we be targeting whatever regulatory or monitoring that we're going to do?
Elon Musk: Well, the open source algorithms and data tend to lag the closed source by 6 to 12 months. But given the rate of improvement that there's actually therefore quite a big difference between the closed source and the open. If things are improving by a factor of, let's say five or more than being a year behind is, you're five times worse. So it's a pretty big difference. And that might be actually an okay situation, but it certainly will get to the point where you've got open source AI that can do that will start to approach human level intelligence or perhaps exceed it. I don't know quite what to do about it. I think it's somewhat inevitable that there'll be some amount of open source and I, I guess I would have a slight bias towards open source because at least you can see what's going on. Whereas closed source, you don't know what's going on. Now, it should be said with AI that even if it's open source, do you actually know what's going on? Because if you've got a gigantic data file and sort of billions of data points or weights and parameters, you can't just read it and see what it's going to do. It's a gigantic file of inscrutable numbers. You can test it when you run it, you can test it. You can run a bunch of tests to see what it's going to do, but it's probabilistic as opposed to deterministic. It's not like traditional programming where you've got very discrete logic and the outcome is very predictable and you can read each line and see what each line is going to do. A neural net is just a whole bunch of probabilities. I mean, it sort of ends up being a giant comma separated value file. It's like our digital guide is a CSV file really. Okay. But that is kind of what it is.
Interviewer: Yeah. Now that point you've Just made is one that we have been talking about a lot because again, conversations, the people are developing the technology make the point that you've just made. It is not like normal software where there's predictability about inputs improving leading to this particular output improving. And as the models iterate and improve, we don't quite know what's going to come out the other end. I think Demis would agree with that, which is why I think there is this bias for, look, we need to get in there while the training runs are being done before the models are released to understand what is this new iteration brought about in terms of capability, which it sounds like you would agree with. I was going to shift gears a little bit. You've talked a lot about human consciousness, human agency, which actually might strike people as strange given that you are known for being such a brilliant innovator and technologist. But it's quite heartfelt when I hear you talk about it and the importance of maintaining that agency in technology and preserving human consciousness. Now, it kind of links to the thing I was going to ask is when I do interviews or talk to people out and about in this job about AI, the thing that comes up most actually is probably not so much the stuff we've been talking about, but jobs. It's what does AI mean for my job? Is it going to mean that I don't have a job or my kids are not going to have a job? Now, my answer as a policymaker, as a leader, is actually AI is already creating jobs. And you can see that in the companies that are starting. Also, the way it's being used is a little bit more as a co pilot, necessarily, versus replacing the person. There's still human agency, but it's helping you do your job better, which is a good thing. And as we've seen with technological revolutions in the past, clearly there's change in the labor market, the amount of jobs. I was quoting an MIT study today that they did a couple of years ago. Something like 60% of the jobs at that moment didn't exist 40 years ago. So hard to predict. And my job is to create an incredible education system, whether it's at school, whether it's retraining people at any point in their career, because ultimately, if we've got a skilled population, they'll be able to keep up with the pace of change and have a good life. But you know that it's still a concern. And what would your kind of observation be on AI and the impact on labor markets and people's jobs and how they should feel about that as they think about this.
Elon Musk: Well, I think we are seeing the most disruptive force in history here where we have for the first time, we will have for the first time something that is smarter than the smartest human. And that, I mean, it's hard to say exactly what that moment is. But there will come a point where no job is needed. You can have a job if you want to have a job for sort of personal satisfaction, but the AI will be able to do everything. So I don't know if that makes people comfortable or uncomfortable. That's why I say if you wish for a magic genie that gives you any wishes you want and there's no limit, you don't have those three limit, three wish limit. Nonsense. You just have as many wishes as you want. So it's both good and bad. One of the challenges in the future will be how do we find meaning in life if you have a magic genie that can do everything you want. I do think it's hard. When there's new technology, it tends to usually follow an S curve. In this case, we're going to be on the exponential portion of the S curve for a long time and you'll be able to ask for anything. It won't be. We won't have universal basic income, we'll have universal high income. So in some sense it'll be somewhat of a leveler or an equalizer because really, I think everyone will have access to this magic genie and you'll be able to ask any question. It'll certainly be good for education. It'll be the best tutor you could and the most patient tutorial. So they're all there. And there will be no shortage of goods and services will be an age of abundance. I think if I'd recommend people read in Banks, the Banks culture books are probably the best envisioning. In fact, not probably. They're definitely by far the best envisioning of an AI future. There's nothing even close. So. So I'd really recommend Banks. I'm a very big fan. All his books are good. Doesn't say which one, all of them. So that'll give you a sense of what is, I guess, a fairly utopian or protopian future with AI which is.
Interviewer: Good from as you said, it's a universal high income, which is a nice phrase and it's good from a materialistic sense sense age of abundance. Actually. That then leads to the question that you pose. Right. I'm someone who believes work gives you meaning. I think a lot about that, as I think work is a good thing. It gives people purpose in their lives. And if you then remove a large chunk of that, what does that mean? And where do you get that? Where do you get that drive, that motivation, that purpose? I mean, you were talking about it. You work a lot of hours.
Elon Musk: I do. No, as I was mentioning when we were talking earlier, I have to somewhat engage in deliberate suspension, suspension of disbelief. Because if I'm. I'm putting so much blood, sweat and tears into a work project and burning the, you know, 3:00am Oil, then I'm like, wait, why am I doing this? I can just wait for the AI to do it. I'm just lashing myself for no reason. Must be a glutton for punishment or something.
Interviewer: So call Demis and tell him to hurry up, and then you can have a holiday. Right? That's the plan. Yeah. No, it's a tricky thing because I think part of our job is to make sure that we can navigate to that very, I think, largely positive place that you're describing. It is, I think, and help people through it between now and then, because these things bring a lot about change in the labor market, as we've seen.
Elon Musk: Yeah. I think it probably is generally a good thing because there are a lot of jobs that are uncomfortable or dangerous or sort of tedious, and the computer will have no problem doing that. Be happy to do that all day long. So it's fun to cook food, but it's not that fun to wash the dishes. But the computer's perfectly happy to wash the dishes. I guess there is. We still have sports where humans compete in the Olympics. And obviously a machine can go faster than any human. But we still have. We still. Humans race against each other and have these sports competitions against each other, where even though the machines are better, they're still, I guess, competing to see who can be the best human at something. And people do find fulfillment in that. So I guess that's perhaps a good example of how even when machines are faster than us, stronger than us, we still find a way, we still enjoy competing against other humans to at least see who is the best human.
Interviewer: Yeah, that's a good analogy. And we've been talking a lot about managing the risks just before we move on, finish on AI. Just talk a little bit about the opportunities you're engaged in. Lots of different companies, neural being an obvious one, which is doing some exciting stuff. You touched on the thing that I'm probably most excited about, which is in education. And I think many people will have Seen Sal Khan's video from earlier this year's TED Talk about. As you talked about, it's like personal tutor.
Elon Musk: Yeah, personal tutor. An amazing personal tutor.
Interviewer: An amazing personal tutor. And we know the difference in learning. Having that personalized tutor is incredible compared to classroom learning. So if you can have every child have a personal tutor specifically for them, that then just evolves with them over time, that could be extraordinary. So for me, I look at that and I think, gosh, that is within reach at this point. And that's one of the benefits I'm most excited about. When you look at the landscape of things that you see as possible, what is it that you are particularly excited about?
Elon Musk: I think certainly AI tutors are going to be amazing. Perhaps already are. I think there's also perhaps companionship, which may seem odd because how can the computer really be your friend? But if you have an AI that has memory and remembers all of your interactions and has read every. You can say, like, give it permission to read everything you've ever done, so it really will know you better than anyone, perhaps even yourself, and where you can talk to it every day and those conversations build upon each other. You will actually have a great friend, as long as that friend can stay your friend and not get turned off or something. Don't turn off my friends. But I think that will actually be a real thing. And one of my sons sort of has some learning disabilities and has trouble making friends, actually. And I was like, well, you know, he. An AI friend would actually be great for him.
Interviewer: Okay. You know, that was a surprising answer, but that's actually worth reflecting on. So it's really interesting. But we're already seeing it actually as we deliver psychotherapy anyway, now doing far more digitally and by telephone to people. And it's making a huge difference. And you can see a world in which actually AI can provide that social benefit to people. Just a quick question on X and then we should open it up to everybody. You made a change in one of the. Made many changes, but, yeah, quite a few. One of the changes.
Elon Musk: You love that letter. Yeah, I've got a real thing about it.
Interviewer: You really do. You really do. One of the changes which kind of goes into the space that we have to operate in. And this. This balance between free speech and moderation is something we grapple with as politicians. You were grappling with your own version of that and you moved away from a kind of manual, human way of doing it, the moderation to the community notes. And I think it was an interesting change. It's not what everyone else has done, it would be good. What was the reasoning behind that and why do you think that is a better way to do that?
Elon Musk: Yeah, part of the problem is if you empower people as censors, then, well, there's going to be some amount of bias they have and then whoever appoints the censors is effectively in control of information. So then the idea behind Community Notes is, well, how do we have a consensus driven, I mean it's not really censoring, but consensus driven approach to truth. How do we make things the least amount untrue? You can say like one can't perhaps get to pure truth, but you can aspire to be more truthful. So the thing about Community Notes is it doesn't actually delete anything, it simply adds context. Now that context could be this thing is untrue for the following reasons. But importantly, with Community Notes, everything is open source actually. So you can see the software, every line of the software. You can see all of the data that went into a community node and you can independently create that community node. So if you've got, if you see manipulation of the data, you can actually highlight that and say, well, there appears to be some gaming of the system and you can suggest improvements. So it's maximum transparency. Yeah, which is I think combined with.
Interviewer: The kind of wisdom of the crowds and transparency to get to a better answer.
Elon Musk: And really one of the key elements of Community Notes is that in order for a note to be shown, people who have historically disagreed must agree. And there is a bit of AI usage here. So there's populated parameter space around each contributor to Community Notes and then parameter space. So everyone's got basically these vectors associated with them. So it's not as simple as right or left, it's saying it's several hundred vectors because things are more complicated than something right or left. And then we'll do sort of inverse correlation, say like, okay, these people generally disagree, but they agree about this node. Okay, so then that, so then that gives the node credibility. Okay, yeah, that's the core of it and it's working quite well. I've yet to see a note actually be present for more than a few hours. That is incorrect. So the batting average is extremely good. And when I ask, people say, oh, they're worried about Community Notes sort of being disinformational, like send me one. And then they can't. So I think it's quite good. I mean the general aspiration is with the X platform is to inform and entertain the public and to be as accurate as possible and as truthful as possible. Even if someone doesn't like the truth. People don't always like the truth. No, not always, but that's the aspiration. And I think if we stay true to the truth, then I think we'll find that people use the system to learn what is going on. And to learn, I think actually truth pays. So I think it'll be, I mean, assuming you don't want to engage in self delusion, then I think it's the smart move.
Interviewer: Excellent, very helpful. Right, let's open it up to all our guests here. We've got some microphones, they'll come, put your hands up, they'll come and find you. We got. Yes, go for it. Thank you.
Interviewer: Good evening. Alice Bentinck from Entrepreneur First. Thank you for a fascinating conversation. I suppose a question for each of you. Prime Minister, The UK has some of the best universities in the world. We have the talent. What will it take for the UK to be a real breeding ground for unicorn companies? And Elon, being a founder in the UK is still a non obvious career choice for the most exceptional technical talent. What are the cultural elements that we need to put into place to change this? Thank you both.
Interviewer: You want to go first? Go for it.
Elon Musk: Sure. Well, you're right that there are cultural elements where the culture should celebrate creating new companies. And there should be a bias towards supporting small companies because they're the ones that need nurturing. The larger companies really don't need nurturing. So you can think of it sort of like a garden. If it's a little sprout, it needs nurturing. If it's a mighty oak, it doesn't need quite as much. So I think that is a mindset change that is important. But I should mention that London is. London and San Francisco or the Bay Area are really the two centers for, for AI. So London is actually doing very well on that front. I'd say the two leading locations on earth, San Francisco's probably ahead of London, but London's really very strong or London area, Greater London home counties, I guess.
Interviewer: Keep going, keep going.
Elon Musk: So I'm just saying objectively this is the case, but you do need that. You need the infrastructure. You need landlords who are willing to rent to new companies, you need law firms and accountants that are willing to support new companies. And it's generally, it is a mindset change and I think some of that is happening, but I think really it's just culturally people need to decide this.
Interviewer: Is a good thing, actually well, thanks for what you said about the uk. It's something that we work hard on. Lots of people in the room are part of what makes this a fabulous place for innovative companies, including Alice. So, Alice, what I'd say is my job is to get all the nuts and bolts right, make sure that all of you are starting companies, can raise the capital that you need. Everything from your seed funding with our incredible EIS tax reliefs all the way through to your late stage rounds. And we need reform of our pension funds. And the Chancellor's got a bunch of incredible reforms to unlock capital from all the people who have it and deploy it into growth equity. Right. That is a work in progress. We're not there yet, but I think we're making good progress. We need talent, we need people. So that means an education system that prioritizes the things that matter. And you've seen my reforms. I go on about more maths. More maths, more maths, but I think that is important, but also attracting the best and the brightest here. If you look at our fastest growing companies in this country, and I think it's probably the same in the us, over half of them have a non British founder. That tells you we've got to be a place that is open to the world's best and brightest entrepreneurial talent. So the visa regime that we've put in place, I think does that makes it easy for those people to come here and then actually it's the thing that we spent the beginning of the session talking about, the regulation, making sure that we've got a regulatory system that's pro innovation, that. Yeah, of course we always need guardrails on the things that will worry us. But we've got to create a space for people to innovate and do different things. Those are all my jobs. The thing that is tougher is the thing that Elon talked about, which is culture. It's how do you transpose that culture from places like Silicon Valley across the world where people are unafraid to give up the security of a regular paycheck to go and start something and be comfortable with failure. You talk about that a lot. I think you talked about it more when you were playing games. You've got to be comfortable failing and knowing that that's just part of the process. And that is a tricky cultural thing to do overnight. But it's an important part of, I think, creating that kind of environment.
Elon Musk: Yeah. If you don't succeed with your first startup, it shouldn't be sort of a catastrophic career ending thing. It should be, I think generally should be like, well you gave it a good shot and now try again.
Interviewer: Exactly.
Elon Musk: So one thing I was going to mention is obviously creating a company is sort of a high risk, high reward situation. But I don't know quite how it works in the uk. I think it's probably better than continental Europe, but the stock options are very difficult in most parts of Europe. I'm not sure how it is in the uk but if somebody's basically going to risk their life savings and the vast majority of startups fail. So I mean you hear about the startups that succeed, but most companies are, most startups consist of, you know, a massive amount of work followed by failure. That's actually most companies. And so it's a high risk, high reward. And so the high reward part does need to be there for it to make sense.
Interviewer: Yeah, I think that was a very soft pitch for a tax policy that I need Chancellor. But actually I can tell you so I agree. And we have sort of, we have I think relative to certainly European countries, But certainly the U.S. definitely California, a much lower rate of capital gains tax. So for those people who are risking and growing something, we think the reward should be there at the end. So it's 20% capital gains tax rate. And on stock options, I don't know if we've got anyone from Index Ventures in the room. So Index, one of our leading VC funds here, they do a regular report looking at most countries tax treatment of stock options. And you know, when I was Chancellor of Treasury Secretary equivalent, you know, we were, I think down at, we were pretty good, but we were fourth or fifth. And I said we need to, for exactly the reason that you mentioned, this has got to be the best place for innovators. We need to move that up. And I think in the last iteration of that report we had, because of the changes that Jeremy and I have made, we have moved up to, I think second from, from memory. Hopefully that should give you and everyone else some comfort that we recognize that's important because when people work hard and risk things, they should be able to enjoy the rewards of that high risk, high reward. Yeah. And I think we very much have a tax system that supports that. And those are the values that I believe in and I think most of us in this room probably do as well. Right, next question. I've got Seb in front of me and then I'll come over here. Go on, go on.
Interviewer: Sebastian, thanks very much. We've talked about some really big ideas, global changing ideas. I'm really interested, particularly in the context of creation of science and technology, super hubs and so on. How does that map onto the everyday lives of people living in say Austin, Texas? To choose one random or in my case, Nottingham, East Midlands. How do you see that evolving for people every day?
Elon Musk: The sort of everyday effects of AI?
Interviewer: For context, Elon. So Seb runs our equivalent of CVS or Walgreens. So when actually I visited. Right. So he's got millions of people coming in his shops every day and it's making sure how do we make this relevant? I think Seb is your question. How is this relevant to that person? Maybe actually I'll go first on that because I think it's a fair, a fair point. I was just going over with the team a couple of things that we're doing because I was saying how are we doing AI right now that is making a difference to people's lives? And we have this thing called Gov UK which is, which actually when it happened several years ago, was a pioneering thing. All the government information brought together on one website, Gov uk and so you need to get a driving license, passport. Any interaction with government, it was centralized in a very easy, relatively easy to use way. Better than most. Better than most. So we're about to deploy AI across that platform. So that is something that I think several million people a day use. Right. So a large chunk of the population is interacting with gov.uk every single day to do all these day to day tasks. Every one of your customers is doing all those things. And so we're about to deploy AI into that to make that whole process so much easier. Because some people will be like, look, well I'm currently here and I've lost my passport and my flight's in five hours. At the moment that would require how many steps to figure out what you do. Actually when we deploy the AI it should be that you could just literally say that and boom, boom, boom, boom, boom. This is what we're going to do. Walk you through it. That's going to benefit millions and millions of people every single day. Because that's a very practical way in my seat that I can start using this technology to help people in their day to day lives, not just healthcare discoveries and everything else that we're also doing. But I thought that's quite a powerful demonstration of literally your day to day customer seeing actually their just day to day life get a little bit easier because of something that Elon Demis and others in this room have helped create.
Elon Musk: Yeah, exactly. The most immediate thing is just being able to ask, like having a very smart friend that you can ask anything, ask how to make something, how to solve any problem, and it'll tell you so. And obviously companies are going to adopt this, so I think you'll have much better customer service. I guess essentially that'll probably be the first thing you notice. And then we talked about education. So having a tutor. So if you're trying to understand a subject, like having a phenomenal tutor on any subject that's really pretty much there already, almost. I mean, we need to. Obviously AI needs to stop hallucinating before, you know, it can't give you. I mean, we still have a little bit of the problem where it can give you an answer that's confidently wrong with great grammar and bullet points and everything in citations. It was not real, so it has to be. Okay. We need to make sure it's not giving you confidently wrong tutor answers. But that's going to happen pretty quickly where it is actually correct.
Interviewer: I was going to say, for any parent who was homeschooling during COVID and realizing what their kids needed to be helped with, that will come as an enormous relief, I think. Very, very good. Right, have we got. Let's go. Questions over here. Who have we got? We only microphones or. Brent, are you there? Perfect.
Interviewer: Hi, Brent Herman. So, you know, you've spoken eloquently about abundance in the age of Abundance. So it feels obviously with AI, it's everything everywhere, everywhere, all at once. But with robots, and to get the age of abundance, we'll need a lot of robots. I know you're working on robots as well. Are there sort of constraints that we should think of and our politicians should be thinking of that we might get. One country might get heavily behind in robots that can do all these things and enter the age of abundance and therefore be at a strategic disadvantage?
Elon Musk: Well, really anything that can be actuated by a computer is effectively a robot. So you can think of, frankly, Tesla cars, our robots on wheels. Anything that's connected to the Internet is effectively an endpoint actuator for artificial intelligence. So you've got Boston Dynamics, obviously they've been making impressive robots for a while. I think they're at this point mostly owned by Hyundai. So I guess Hyundai's probably going to make robots that are humanoid and some rather interesting shapes that I wasn't anticipating. Like the one that looks like a. Has wheels and looks sort of like a kangaroo on wheels. I'm not sure what that is, but looks a little demented, frankly. But there's going to be all sorts of robots. You've got the company Dyson in the uk, which I think does some pretty impressive things. I think the UK will not be behind, actually, on that front. UK also has arm, which is really the best, one of the best, perhaps the best in chip design in the world. Tesla uses a lot of ARM technology. Almost everyone does, actually. So I think the UK is in a strong position. Germany obviously makes a lot of robots, industrial robots. I mean, I think generally countries that make robots of any kind, even if they seem somewhat conventional, will be fine. I do think there is a safety concern, especially with humanoid robots, because at least the car can't chase you into this building, not very easily, or chase you up a tree, or you can sort of run up a flight of stairs and get away from a Tesla. I think there's a Stephen King movie about that, if your car gets possessed, but if you have a humanoid robot, it can basically chase you anywhere. So I think we should have some kind of hardwired local cutoff that you can't update from the Internet. So anything that can be software updated from the Internet obviously can be overridden. But if you have a local sort of off switch where you perhaps say a keyword or something, and then that puts the robot into a safe state, some kind of localized safe state ability, an off switch where you don't have to get too close to the robot. I don't know if we've got millions of these things going all over the place.
Interviewer: You're not selling it. Just, you know.
Elon Musk: I know. I'm saying this is something we should be quite concerned about because if a robot can follow you anywhere, then what if they just one day get a software update and they're not so friendly anymore? We've got a James Cameron movie on our hands.
Interviewer: It's funny you say that because in our session that we had today, I would say who. They made exactly the same point, right? So we're talking about. They're talking about movies, actually, without mentioning James Cameron. They're talking about James Cameron movies. They're saying, if you think about it, it's not just those movies, but any of these movies. Trains, subways, metros, cars, buses. They said all these movies with the same plot fundamentally all end with the person turning it off, right. Or finding a way to shut the thing down. And they were making the same point that, that you were about the importance of actual physical off switches. And so all the technology is great. But fundamentally this same movie has played out 50 times. We've all watched it and it all fundamentally the point I'm referring to.
Elon Musk: Right.
Interviewer: It all ends in pretty much the same way with someone finding their way to just do the thing. Which is kind of interesting that you said a similar point. Right. It's not the obvious place you'd go.
Elon Musk: To, but maybe that could be one of the tests for the AI. We should say blank is your favorite Jameis Cameron movie. Fill in the blank.
Interviewer: Yeah, excellent. Right, yes, we got over there. Yep, perfect.
Interviewer: Hi, question for you both. So I'm a founder of a AI and ML scale up in the third center for AI, which is Leeds in the north of England. A bit biased since the launch of ChatGPT three months after that, we saw a real increase in phishing attacks using much more sophisticated language patterns. What do we do to protect businesses, consumers, that they trust this technology better and how do we bring them along that journey with us?
Elon Musk: Well, I think we shouldn't trust it that much, actually. It is actually quite a significant challenge because we're getting to the point where even open source AI can pass human capture tests. So, you know, this was, are you a human? Identify all the traffic lights in this picture. You're like, okay, it's going to have no problem doing that. In fact, it'll do it better than a human and faster than a human. So we're like, how do you. It's a point at which it's a better human, better passing human tests than humans, then, well, what tests actually make sense? That is a real problem. I don't actually have a good solution to it. One of the things we're trying to figure out on the X platform is how to deal with that. Because we really are at the point where even with open source, readily available AI, you don't need to be leading the field. You can actually be better than humans at passing these tests. And that's sort of why we think, well, perhaps we should charge a dollar or a pound a year. It's a very tiny amount of money, but it's, it still makes it prohibitively expensive to make a million bots. Especially if you need a million payment methods, then you run out of stolen credit cards pretty quickly. So that's sort of where we're thinking like we might have to sort of just charge some very tiny amount of money, 0.3 cents a day effectively to deal with the onslaught of AI powered bots. And that is still a growing problem, but it will be, I think, perhaps an insurmountable problem next year. And then you have to worry about, well, manipulation of information, making something seem very popular, when in fact it is not because it's getting boosted by all these likes and reposts from AI powered bots. So that's why I sort of think somewhat inevitably it leads to some small payment in order to dramatically increase the cost of a bot. So I think, frankly, I think probably any social media system that doesn't do that will simply be overrun by bots.
Interviewer: I think my general answer would be we need to show that we are on top of mitigating the risks. Right. So people can trust the technology. That's what actually the last couple of days has been about on the Safety Summit is just showing, you know, we're investing in the Safety Institute, having the people who can do the research on these things to figure out how we mitigate against them. And we have to do it fast and we have to keep iterating it because I think all of us probably in this room believe that the technology can be incredibly powerful. But we've got to make sure we bring people along that journey with us, that we're handling the risks that are there. And as there's a job to do and the last couple of days I think we made good progress on it because we want to focus on the positives and manage these things. But that requires action. And that's what the last couple of days has been about. Your, your story, your analogy. There was part of the research that actually, you know, the team working on the task force here published and presented yesterday. I don't know if you saw it was, which is essentially that it was using AI to create a ton of fake profiles on social media and then infiltrate particular groups with particular information. And at the moment that is said to your point is like cost free.
Elon Musk: It's getting to the point where it's like really you're going to have 100 for a penny sort of thing. Ridiculous.
Interviewer: And if you think about some of these social networks at quite a neighborhood or town level, it's not that many fake profiles that you need to quickly create. Suddenly they're everywhere and there's some local issue that might be of importance and you know, the team have run versions of how that would look like and suddenly they're interacting with everybody and then spreading misinformation around. Yeah, that's a real challenge. We literally, as part of the research that we published on misinformation yesterday, it's a real challenge.
Elon Musk: Yeah, exactly to your point, I mean, the images you don't even need to steal. Somebody's a picture because that's traceable. But you can actually just say, create a new image of a person, realistic looking, but doesn't exist, and then create a biography, realistic, but doesn't exist, and do that en masse. And practically the only way you'll be able to tell is that the grammar is too good to give away. No typos. Come on.
Interviewer: Now I'm getting waved at because I think we are out of time. I. I don't want to take one very brief last question and let's make a good one. Yes, sir. Go on. You're right in front of me. Go on.
Elon Musk: Thank you for the opportunity.
Interviewer: Elon, question for you related to X platform. Are there simple things we can do, especially when it comes to visual media? You alluded to the fact that it's fairly straightforward and effectively free to make people like yourself say and do things that you never said or did.
Elon Musk: Yeah.
Interviewer: Can we do something like cryptographically signed media? I'm from Adobe, we're working on this project. Yeah, Twitter was a member. Love to see X come back.
Interviewer: Okay.
Interviewer: Digitally signed media to indicate not only what was created by AI, but what came from a camera, what was real, to imbue a sense of trust in media that can go viral.
Elon Musk: That sounds like a good idea actually. So some way of authenticating would be good. So, yeah, that sounds like a good idea. We should probably do it.
Interviewer: There you go, actually on that point. So I've already. This is particularly pertinent for people in my job. Right. And I've already had a situation happen to me with a doctored image that goes everywhere negative. By the time everyone realizes, well, that's fake and we should stop sending it, the damage is, the damage is done. And actually we were again reflecting today, if you think next year you've got elections in, you know, I think the us, India, I think Indonesia, probably here. There you go. Massive news. And actually you've got just an enormous chunk of the world's population is voting next year. Right. And you've got EU elections as well. Actually, just these issues are right in front of us. Next year is where big elections across the globe. Probably the first set of elections where this has been a real issue. So figuring out how we manage that is, I think, kind of mission critical for the people who want the integrity of our democracy.
Elon Musk: Yeah. I mean, some of it is quite entertaining. Like the Pope in the puffer jacket. Have you seen that one?
Interviewer: I haven't.
Elon Musk: That's amazing. But I mean, I still run into people who think that's real. I'm like, well, what are the odds he's wearing a puffer jacket in July in Rome, you know, be sweating. But it actually looked quite dashing. In fact, I think AI Fashion is going to be a real thing. So I don't do include, like, we live in the most interesting times, and I think this is. It is like 80% likely to be good and 20% bad. And I think if we're cognizant and careful about the bad part, on balance, actually, it will be the future that we want or the future that is preferable. And it actually will be somewhat of a leveler, an equalizer in the sense that I think everyone will have access to goods and services and education. And so I think probably it leads to more human happiness. So I guess I'd probably leave on an optimistic note.
Interviewer: Perfect.
Elon Musk: Yeah.
Interviewer: That is a great note to end on. I think we all want that better future. We think it's there. The promise of it is certainly there. Lots of people in this room, including yourselves, are working hard to make it happen. Our job in government is to make sure it happens safely. But on the basis of this conversation in the last couple of days, I'm certainly leaving more confident that we can make that happen. It's been a huge privilege and a pleasure to have you here.
Elon Musk: Well, thank you. Thank you very much for having me.
